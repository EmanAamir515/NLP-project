{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1BAWhmXkVr05FDzOD8KyZR3Jj2acpswG4",
      "authorship_tag": "ABX9TyMrCqleoigwZEeHDePsom78",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmanAamir515/NLP-project/blob/main/NLP_intial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch4RcVYsTXDh",
        "outputId": "c6090a81-3375-4bb6-c312-c66c635bee45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can access your NLP_dataset folder\n",
        "import os\n",
        "\n",
        "# List contents of your NLP_dataset folder\n",
        "nlp_path = '/content/drive/MyDrive/NLP_dataset/'\n",
        "if os.path.exists(nlp_path):\n",
        "    print(\"Files in NLP_dataset folder:\")\n",
        "    print(os.listdir(nlp_path))\n",
        "else:\n",
        "    print(\"NLP_dataset folder not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xih1hyj1LSjZ",
        "outputId": "6cb4c3c9-4040-401d-9e00-f992219dbe16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in NLP_dataset folder:\n",
            "['joy_sent.txt', 'sadness_sent.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "nlp_path = Path('/content/drive/MyDrive/NLP_dataset/')\n",
        "joy_file = nlp_path / 'joy_sent.txt'\n",
        "sad_file = nlp_path / 'sadness_sent.txt'\n",
        "\n",
        "def txt_to_df(txt_path, label):\n",
        "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
        "        lines = [line.strip() for line in f if line.strip()]\n",
        "    return pd.DataFrame({'text': lines, 'label': label})\n",
        "\n",
        "df_joy = txt_to_df(joy_file, 'joy')\n",
        "df_sad = txt_to_df(sad_file, 'sadness')\n",
        "\n",
        "df = pd.concat([df_joy, df_sad], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(df.shape)\n",
        "df.head()\n",
        "# Save to Drive for later\n",
        "df.to_csv(nlp_path / 'emotion_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWfUbAV0LjJl",
        "outputId": "06253956-b16b-4c71-ea79-d062a35be085"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2283, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Zhrspk7YDafH"
      }
    }
  ]
}